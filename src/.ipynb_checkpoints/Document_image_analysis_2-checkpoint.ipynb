{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Image Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pytesseract\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import uuid\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LooseVersion ('5.0.0-alpha.20190623')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "pytesseract.get_tesseract_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathing\n",
    "class Pathing:\n",
    "    def __init__(self, dataset=None):\n",
    "        self._root = Path().absolute().parent\n",
    "        self._dataset = dataset\n",
    "        self._img_path = None\n",
    "        self._dir_path = None\n",
    "        self.data =  Path.joinpath(self.root, \"data\")\n",
    "        \n",
    "    @property\n",
    "    def root(self):\n",
    "        return self._root\n",
    "    \n",
    "    @root.setter\n",
    "    def root(self, v):\n",
    "        self._root = v\n",
    "        self.data =  Path.joinpath(self.root, \"data\")\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "    \n",
    "    @dataset.setter\n",
    "    def dataset(self, v): \n",
    "        self._dataset = v\n",
    "        \n",
    "    @property\n",
    "    def img_path(self):\n",
    "        return self._img_path\n",
    "    \n",
    "    @img_path.setter\n",
    "    def img_path(self, loc):\n",
    "        if not self.dir_path:\n",
    "            raise AttributeError('Direction path needs to be set')\n",
    "        self._img_path = Path.joinpath(self.dir_path, loc)\n",
    "    \n",
    "    @property\n",
    "    def dir_path(self):\n",
    "        return self._dir_path\n",
    "    \n",
    "    @dir_path.setter\n",
    "    def dir_path(self, loc):\n",
    "        if not self.dataset:\n",
    "            self._dir_path = Path.joinpath(self.data, loc)\n",
    "            \n",
    "            if self.img_path:\n",
    "                self.img_path = Path.joinpath(self.dir_path,self.img_path)\n",
    "\n",
    "        self._dir_path = Path.joinpath(Path.joinpath(self.data, self.dataset), loc)\n",
    "        \n",
    "        if self.img_path:\n",
    "            self.img_path = Path.joinpath(self.dir_path, self.img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathing_ghega = Pathing('ghega-dataset')\n",
    "pathing_accident = Pathing('accident-dataset')\n",
    "pathing_ghega.dir_path = r'datasheets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x2160 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv.imread(str(pathing.img_path),0)\n",
    "\n",
    "ret,thresh = cv.threshold(img,227,355,cv.THRESH_BINARY_INV)\n",
    "\n",
    "plt.figure(figsize=(35,30))\n",
    "plt.subplot(2,3,5)\n",
    "#plt.imshow(thresh,'gray')\n",
    "plt.title('BINARY_INV')\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_to_dict(img_dir):\n",
    "    \n",
    "    img_dict = defaultdict(list)\n",
    "    labels = []\n",
    "    id_ = 0\n",
    "    columns = ['id', 'label']\n",
    "    ext = \"png\"\n",
    "    for label in glob.glob('{dir}/*'.format(dir=img_dir)):\n",
    "        label = Path(label).name\n",
    "        labels.append(label)\n",
    "   \n",
    "    for label, idx in zip(labels, range(0, len(labels))):\n",
    "        for filename in glob.glob('{path}/{label}/*.png'.format(path=img_dir, label=label)):\n",
    "            img_dict[columns[0]].append(filename)\n",
    "            img_dict[columns[1]].append(label)\n",
    "        print(\"finished writing {percentage} percent...\".format(percentage=math.ceil((100/len(labels))*(idx+1))))\n",
    "    \n",
    "    return img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing 9 percent...\n",
      "finished writing 17 percent...\n",
      "finished writing 25 percent...\n",
      "finished writing 34 percent...\n",
      "finished writing 42 percent...\n",
      "finished writing 50 percent...\n",
      "finished writing 59 percent...\n",
      "finished writing 67 percent...\n",
      "finished writing 75 percent...\n",
      "finished writing 84 percent...\n",
      "finished writing 92 percent...\n",
      "finished writing 100 percent...\n"
     ]
    }
   ],
   "source": [
    "df_dict_ghega = data_to_dict(pathing_ghega.dir_path)\n",
    "df_dict_accident = data_to_dict(pathing.pathing_ghega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\chris\\\\develop\\\\OCR\\\\data\\\\ghega-dataset\\\\datasheets/central-zener-1\\\\document-000-118454.in.000.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(df_dict)\n",
    "df['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = r'data.csv'\n",
    "#df.to_csv(file_name, index=False, header=True)\n",
    "#df = pd.read_csv(r'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of train dataset: 198\n",
      "amount of test data: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>taiwan-schottky-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>rohm-zener-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>diodes-zener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>central-zener-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>taiwan-zener</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id              label\n",
       "211  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...  taiwan-schottky-2\n",
       "155  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...       rohm-zener-1\n",
       "116  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...       diodes-zener\n",
       "1    C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...    central-zener-1\n",
       "238  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...       taiwan-zener"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "print(\"amount of train dataset: {len_train}\\namount of test data: {len_test}\".format(len_train=len(train), len_test=len(test)))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=train, x_col='id', y_col='label', class_mode='categorical', target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(dataframe=test, x_col='id', y_col='label', class_mode='categorical', target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "20/20 [==============================] - 113s 6s/step - loss: 2.2403 - acc: 0.2575 - val_loss: 2.2086 - val_acc: 0.3800\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 85s 4s/step - loss: 2.1784 - acc: 0.2547 - val_loss: 2.2094 - val_acc: 0.3800\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 2.2027 - acc: 0.2490 - val_loss: 2.2065 - val_acc: 0.3800\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 2.2007 - acc: 0.2504 - val_loss: 2.2228 - val_acc: 0.3800\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 2.1242 - acc: 0.2936 - val_loss: 2.1849 - val_acc: 0.3800\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 85s 4s/step - loss: 2.0411 - acc: 0.3331 - val_loss: 2.1339 - val_acc: 0.4400\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.9973 - acc: 0.3660 - val_loss: 2.0535 - val_acc: 0.4600\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 82s 4s/step - loss: 1.9051 - acc: 0.3926 - val_loss: 1.9036 - val_acc: 0.4800\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 87s 4s/step - loss: 1.7074 - acc: 0.4892 - val_loss: 1.7746 - val_acc: 0.5400\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 1.4911 - acc: 0.5491 - val_loss: 1.5738 - val_acc: 0.6000\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 1.2842 - acc: 0.5997 - val_loss: 1.4130 - val_acc: 0.6400\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 1.2362 - acc: 0.6211 - val_loss: 1.2997 - val_acc: 0.6600\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 1.0256 - acc: 0.7115 - val_loss: 1.1752 - val_acc: 0.6200\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 78s 4s/step - loss: 0.8987 - acc: 0.7274 - val_loss: 1.0461 - val_acc: 0.6800\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.7802 - acc: 0.7620 - val_loss: 0.9549 - val_acc: 0.6800\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.7228 - acc: 0.7782 - val_loss: 0.8333 - val_acc: 0.7000\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.6420 - acc: 0.7980 - val_loss: 0.7689 - val_acc: 0.7600\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 0.5908 - acc: 0.8091 - val_loss: 0.6767 - val_acc: 0.7800\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.5584 - acc: 0.8056 - val_loss: 0.6629 - val_acc: 0.8000\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 0.4109 - acc: 0.8805 - val_loss: 0.5308 - val_acc: 0.8200\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 0.3752 - acc: 0.8930 - val_loss: 0.4732 - val_acc: 0.8000\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 0.3128 - acc: 0.9198 - val_loss: 0.4158 - val_acc: 0.8600\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.2675 - acc: 0.9229 - val_loss: 0.3856 - val_acc: 0.8600\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.2207 - acc: 0.9481 - val_loss: 0.3744 - val_acc: 0.8200\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.2633 - acc: 0.9207 - val_loss: 0.2910 - val_acc: 0.8800\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 78s 4s/step - loss: 0.1630 - acc: 0.9558 - val_loss: 0.2816 - val_acc: 0.9000\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.1453 - acc: 0.9560 - val_loss: 0.2566 - val_acc: 0.9000\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.1070 - acc: 0.9670 - val_loss: 0.1807 - val_acc: 0.9600\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0882 - acc: 0.9811 - val_loss: 0.2698 - val_acc: 0.8800\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.1214 - acc: 0.9557 - val_loss: 0.2061 - val_acc: 0.9200\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 79s 4s/step - loss: 0.0963 - acc: 0.9668 - val_loss: 0.1691 - val_acc: 0.9600\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 446s 22s/step - loss: 0.0673 - acc: 0.9858 - val_loss: 0.2042 - val_acc: 0.9600\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0478 - acc: 0.9906 - val_loss: 0.1981 - val_acc: 0.9600\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0501 - acc: 0.9890 - val_loss: 0.1679 - val_acc: 0.9400\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0576 - acc: 0.9906 - val_loss: 0.1928 - val_acc: 0.9600\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.0429 - acc: 0.9874 - val_loss: 0.1694 - val_acc: 0.9600\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.0343 - acc: 0.9890 - val_loss: 0.1592 - val_acc: 0.9600\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0275 - acc: 0.9937 - val_loss: 0.1847 - val_acc: 0.9200\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0326 - acc: 0.9921 - val_loss: 0.1698 - val_acc: 0.9600\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0174 - acc: 0.9984 - val_loss: 0.1775 - val_acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ca4a4e080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(optimizers.rmsprop(lr=0.0001) , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "              \n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=20,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=20,\n",
    "                    epochs=40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taiwan-switching\n",
      "C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\datasheets/taiwan-switching\\document-003-114330.in.000.png\n",
      "\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df['label'][220])\n",
    "print(df['id'][220])\n",
    "im = cv.imread(df['id'][220])\n",
    "print()\n",
    "im = cv.resize(im, (32, 32))\n",
    "\n",
    "pred = [im]\n",
    "pred = np.stack(pred, axis=0)\n",
    "x_pred = model.predict_classes(pred)\n",
    "print(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
