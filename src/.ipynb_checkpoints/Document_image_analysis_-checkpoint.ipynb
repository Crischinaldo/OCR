{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Image Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pytesseract\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import uuid\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LooseVersion ('5.0.0-alpha.20190623')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "#pytesseract.get_tesseract_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathing\n",
    "class Pathing:\n",
    "    def __init__(self, dataset=None):\n",
    "        self._root = Path().absolute().parent\n",
    "        self._dataset = dataset\n",
    "        self._img_path = None\n",
    "        self._dir_path = None\n",
    "        self.data =  Path.joinpath(self.root, \"data\")\n",
    "        \n",
    "    @property\n",
    "    def root(self):\n",
    "        return self._root\n",
    "    \n",
    "    @root.setter\n",
    "    def root(self, v):\n",
    "        self._root = v\n",
    "        self.data =  Path.joinpath(self.root, \"data\")\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "    \n",
    "    @dataset.setter\n",
    "    def dataset(self, v): \n",
    "        self._dataset = v\n",
    "        \n",
    "    @property\n",
    "    def img_path(self):\n",
    "        return self._img_path\n",
    "    \n",
    "    @img_path.setter\n",
    "    def img_path(self, loc):\n",
    "        if not self.dir_path:\n",
    "            raise AttributeError('Direction path needs to be set')\n",
    "        self._img_path = Path.joinpath(self.dir_path, loc)\n",
    "    \n",
    "    @property\n",
    "    def dir_path(self):\n",
    "        return self._dir_path\n",
    "    \n",
    "    @dir_path.setter\n",
    "    def dir_path(self, loc):\n",
    "        if not self.dataset:\n",
    "            self._dir_path = Path.joinpath(self.data, loc)\n",
    "            \n",
    "            if self.img_path:\n",
    "                self.img_path = Path.joinpath(self.dir_path,self.img_path)\n",
    "\n",
    "        self._dir_path = Path.joinpath(Path.joinpath(self.data, self.dataset), loc)\n",
    "        \n",
    "        if self.img_path:\n",
    "            self.img_path = Path.joinpath(self.dir_path, self.img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathing = Pathing('ghega-dataset')\n",
    "pathing.dir_path = r'datasheets/central-zener-1'\n",
    "pathing.img_path = r'document-000-118454.in.000.png'\n",
    "#img = Image.open(pathing.img_path)\n",
    "#img.resize((500, 800), Image.ANTIALIAS)\n",
    "\n",
    "pathing.dir_path = r'datasheets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x2160 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv.imread(str(pathing.img_path),0)\n",
    "\n",
    "ret,thresh = cv.threshold(img,227,355,cv.THRESH_BINARY_INV)\n",
    "\n",
    "plt.figure(figsize=(35,30))\n",
    "plt.subplot(2,3,5)\n",
    "#plt.imshow(thresh,'gray')\n",
    "plt.title('BINARY_INV')\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_to_dict(img_dir):\n",
    "    \n",
    "    img_dict = defaultdict(list)\n",
    "    labels = []\n",
    "    id_ = 0\n",
    "    columns = ['id', 'label']\n",
    "    ext = \"png\"\n",
    "    for label in glob.glob('{dir}/*'.format(dir=img_dir)):\n",
    "        label = Path(label).name\n",
    "        labels.append(label)\n",
    "   \n",
    "    for label, idx in zip(labels, range(0, len(labels))):\n",
    "        for filename in glob.glob('{path}/{label}/*.png'.format(path=img_dir, label=label)):\n",
    "           # im = cv.imread(filename)\n",
    "           # im = cv.resize(im, (32, 32))\n",
    "           # im = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "           # np_im = np.array(im)\n",
    "           # for col in columns:\n",
    "            img_dict[columns[0]].append(filename)\n",
    "            img_dict[columns[1]].append(label)\n",
    "            # img_dict[columns[2]].append(np_im)\n",
    "           \n",
    "           \n",
    "        print(\"finished writing {percentage} percent...\".format(percentage=math.ceil((100/len(labels))*(idx+1))))\n",
    "    \n",
    "    return img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing 9 percent...\n",
      "finished writing 17 percent...\n",
      "finished writing 25 percent...\n",
      "finished writing 34 percent...\n",
      "finished writing 42 percent...\n",
      "finished writing 50 percent...\n",
      "finished writing 59 percent...\n",
      "finished writing 67 percent...\n",
      "finished writing 75 percent...\n",
      "finished writing 84 percent...\n",
      "finished writing 92 percent...\n",
      "finished writing 100 percent...\n"
     ]
    }
   ],
   "source": [
    "df_dict = data_to_dict(pathing.dir_path)\n",
    "#df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\chris\\\\develop\\\\OCR\\\\data\\\\ghega-dataset\\\\datasheets/central-zener-1\\\\document-000-118454.in.000.png'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(df_dict)\n",
    "df['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = r'data.csv'\n",
    "#df.to_csv(file_name, index=False, header=True)\n",
    "#df = pd.read_csv(r'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of train dataset: 198\n",
      "amount of test data: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>sharp-led-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>diodes-zener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>sharp-led-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>taiwan-zener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...</td>\n",
       "      <td>diodes-zener</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id         label\n",
       "173  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...   sharp-led-1\n",
       "68   C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...  diodes-zener\n",
       "192  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...   sharp-led-2\n",
       "239  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...  taiwan-zener\n",
       "111  C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\...  diodes-zener"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "print(\"amount of train dataset: {len_train}\\namount of test data: {len_test}\".format(len_train=len(train), len_test=len(test)))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=train, x_col='id', y_col='label', class_mode='categorical', target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 validated image filenames belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(dataframe=test, x_col='id', y_col='label', class_mode='categorical', target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "20/20 [==============================] - 133s 7s/step - loss: 2.2854 - acc: 0.2402 - val_loss: 2.2700 - val_acc: 0.2800\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 75s 4s/step - loss: 2.1690 - acc: 0.3062 - val_loss: 2.2533 - val_acc: 0.2800\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 76s 4s/step - loss: 2.2157 - acc: 0.2741 - val_loss: 2.2474 - val_acc: 0.2800\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 86s 4s/step - loss: 2.1549 - acc: 0.2823 - val_loss: 2.2258 - val_acc: 0.2800\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 94s 5s/step - loss: 2.0903 - acc: 0.3205 - val_loss: 2.1908 - val_acc: 0.2800\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 82s 4s/step - loss: 2.0925 - acc: 0.3043 - val_loss: 2.1132 - val_acc: 0.3800\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 84s 4s/step - loss: 1.9528 - acc: 0.3756 - val_loss: 2.0448 - val_acc: 0.4600\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.8067 - acc: 0.4343 - val_loss: 1.8270 - val_acc: 0.5000\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 83s 4s/step - loss: 1.5940 - acc: 0.5225 - val_loss: 1.6681 - val_acc: 0.5000\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 84s 4s/step - loss: 1.5061 - acc: 0.5459 - val_loss: 1.5129 - val_acc: 0.5200\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 83s 4s/step - loss: 1.3674 - acc: 0.5631 - val_loss: 1.3881 - val_acc: 0.5200\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 86s 4s/step - loss: 1.1609 - acc: 0.6549 - val_loss: 1.2299 - val_acc: 0.6200\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 84s 4s/step - loss: 1.0502 - acc: 0.6623 - val_loss: 1.1168 - val_acc: 0.6400\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 93s 5s/step - loss: 0.9469 - acc: 0.7068 - val_loss: 1.0264 - val_acc: 0.6400\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.8786 - acc: 0.7233 - val_loss: 0.9518 - val_acc: 0.6800\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.7867 - acc: 0.7537 - val_loss: 0.8577 - val_acc: 0.7000\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 84s 4s/step - loss: 0.8446 - acc: 0.7535 - val_loss: 0.8112 - val_acc: 0.7000\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 83s 4s/step - loss: 0.6433 - acc: 0.8108 - val_loss: 0.7614 - val_acc: 0.7600\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.6410 - acc: 0.8125 - val_loss: 0.6907 - val_acc: 0.7600\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.5708 - acc: 0.8218 - val_loss: 0.6421 - val_acc: 0.7600\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.4806 - acc: 0.8298 - val_loss: 0.5900 - val_acc: 0.8200\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.4400 - acc: 0.8570 - val_loss: 0.4933 - val_acc: 0.8000\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.3886 - acc: 0.8709 - val_loss: 0.4535 - val_acc: 0.8200\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.3777 - acc: 0.8863 - val_loss: 0.4341 - val_acc: 0.8600\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.2808 - acc: 0.9039 - val_loss: 0.3601 - val_acc: 0.9000\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.2714 - acc: 0.9100 - val_loss: 0.3268 - val_acc: 0.9000\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 82s 4s/step - loss: 0.2098 - acc: 0.9338 - val_loss: 0.3012 - val_acc: 0.9000\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.2160 - acc: 0.9292 - val_loss: 0.2825 - val_acc: 0.8800\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 85s 4s/step - loss: 0.1954 - acc: 0.9418 - val_loss: 0.2138 - val_acc: 0.9400\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.1658 - acc: 0.9542 - val_loss: 0.2006 - val_acc: 0.9600\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.1404 - acc: 0.9654 - val_loss: 0.1900 - val_acc: 0.9400\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.1351 - acc: 0.9572 - val_loss: 0.1627 - val_acc: 0.9600\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.1168 - acc: 0.9635 - val_loss: 0.1771 - val_acc: 0.9400\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 81s 4s/step - loss: 0.1180 - acc: 0.9572 - val_loss: 0.1879 - val_acc: 0.9400\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 80s 4s/step - loss: 0.0973 - acc: 0.9748 - val_loss: 0.1543 - val_acc: 0.9400\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 88s 4s/step - loss: 0.0809 - acc: 0.9749 - val_loss: 0.1897 - val_acc: 0.9600\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 91s 5s/step - loss: 0.0766 - acc: 0.9763 - val_loss: 0.1172 - val_acc: 0.9800\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 87s 4s/step - loss: 0.0716 - acc: 0.9843 - val_loss: 0.2139 - val_acc: 0.9000\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.0602 - acc: 0.9843 - val_loss: 0.0871 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 102s 5s/step - loss: 0.0448 - acc: 0.9874 - val_loss: 0.0936 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(optimizers.rmsprop(lr=0.0001) , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "              \n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=20,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=20,\n",
    "                    epochs=40)\n",
    "\n",
    "\n",
    "model.save('invoice_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taiwan-switching\n",
      "C:\\Users\\chris\\develop\\OCR\\data\\ghega-dataset\\datasheets/taiwan-switching\\document-003-114330.in.000.png\n",
      "\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df['label'][220])\n",
    "print(df['id'][220])\n",
    "im = cv.imread(df['id'][220])\n",
    "print()\n",
    "im = cv.resize(im, (32, 32))\n",
    "\n",
    "pred = [im]\n",
    "pred = np.stack(pred, axis=0)\n",
    "x_pred = model.predict_classes(pred)\n",
    "print(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
