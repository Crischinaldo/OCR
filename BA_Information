**** BACHELORARBEIT ****

**** FUNCTIONS ****

np.stack: stacks x 1D arrays into a matrix with shapes of given arrays
np.vstack: stack x arrays rowwise
np.hstack: stack x arrays columnwise



**** QUELLEN ****

allg.: https://scholar.google.de

ocr-api: https://ocr.space

deep learning: https://hackernoon.com/latest-deep-learning-ocr-with-keras-and-supervisely-in-15-minutes-34aecd630ed8

text-recognition: best path decoding algorithm

ocr-deep-learning: https://nicholastsmith.wordpress.com/2017/10/14/deep-learning-ocr-using-tensorflow-and-python/

TFANN: A neural network module containing implementations of MLP, and CNN networks in TensorFlow.

https://towardsdatascience.com/a-gentle-introduction-to-ocr-ee1469a201aa

deep learning, tesseract, ocr: https://www.learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/

**** OCR ****

The method of extracting text from images is also called Optical Character Recognition (OCR) or sometimes simply text recognition.

bsp. code: https://www.pyimagesearch.com/2017/07/10/using-tesseract-ocr-python/

Automatisierte Texterkennung innerhalb von Bildern

Deep-Learning netzwerke verwendet auf das OCR-Problem - Mit Python und Tensorflow. TFANN als Lib für CNN mit ANNC als Klasse.

OCR Texterkennung über API oder Local?

Generell: Text von jeden möglichen Bild extrahieren. Texterkennungsprozesse sind auch Straßenschilder, Captchas oder Nummerschilder zu lesen.

Attribute der OCR-Aufgaben:

1. Textdichte: sollte möglicht dicht sein. 

2. Textstruktur: Text auf Seite sollte strukturiert sein, meist in strengen Zeilen.
dense (as in printed document) or sparse (As text in the wild)


3. Schriften: Gedruckte Schriften sind einfacher als handgeschriebene Zeichen

4. Zeichentyp: Text kann in anderer Sprache verfasst sein, die sehr unterschiedlich sein kann. 

5. Artefakte: Es können Ausreißer vorkommen.

6. Ort: Einige Aufgaben enthalten aussgeschnittene/zentrierte Texte während sich in anderen Aufgaben Text an zufälligen Stellen im Bild befindet.

Nachdem die Stufe der Zeilen/wörter erkannt wurden ist können wir auf mögliche Lösungen auswählen:

1. Klassische Computer vision techniken

2. Spezialisiertes Deep Learning.

3. Standart Deep Learning (Detection)

**** TESSERACT ****

Arbeitet am besten wenn eine saubere segementierung des Vordergrundtextes zum Hintergrund. Um dies zu gewährleisten neigt man zu domänenspezifische Bildklassifikatoren und detektoren zu trainieren.

Funktioniert nur mit einer bestimmten Sorte von Image Dateien. PDF's müssen in kleine dateien gesplittet werden, damit darauf OCR angewendet werden können.

*** Handwritten Text Recognition ***

Using Keras lstm: https://towardsdatascience.com/build-a-handwritten-text-recognition-system-using-tensorflow-2326a3487cd5

**** Beispiel Repos ****

OCR with lstm RCNN architecture
https://github.com/vinayakkailas/Deeplearning-OCR

OCR-Model
https://github.com/tensorflow/models/tree/master/research/attention_ocr

Single Shot MultiBox Detector
https://github.com/pierluigiferrari/ssd_keras

Keras Example lstm
https://keras.io/examples/image_ocr/


 *** Recurrent neuronal network architecture - LTSM - ***

 LSTM: Populärste Netzarchitektur zur Erkennung von Sequenzstrukturierten Input. Default Architektur zur
 Erkennung von Text. 

 ** Ablauf **
 CNN: Der Input in Form eines Images wird in CNN Layers gefüttert. Die Schichten sind dazu trainiert um relevante Merkmale aus dem Bild zu extrahieren. Jede Schicht führt 3 Operationen aus:
 1. Faltungsoperation (convolution operation): TODO


 Quelle: https://en.wikipedia.org/wiki/Connectionist_temporal_classification
 CTC: Typ von Outputs eines neuronalen Netzwerks und gleichzeitig Bewertungsfunktion zum trainieren von RNNs (wiederkehrende Neuronale Netzwerke) wie LSTM-Netzwerke. Diese Netzwerke sind darauf ausgelegt Sequenzprobleme zu lösen wo das Timing variabel ist. Es kann u.A. zum erkennen von handschriftlichen Text genutzt werden. CTC bezieht sich auf die Ausgaben und die Bewertung unabhängig von den Aufbau der neuronales Netzstruktur.
 Der Input ist eine Sequenz aus Beobachtungen und die Ausgaben sind eine Sequenz von Klassen (labels) welche auch leere Ausgaben enthalten können. Die Schwierigkeit des trainings ergibt sich daraus, dass es viel mehr Beobachtungen als Klassen gibt.
 Ein CTC-Netzwerk hat eine kontinuierliche Ausgabe (zb. Softmax), die durch Training angepasst wird, um die Wahrscheinlichkeit einer Klasse zu modellieren.
 CTC-Scores können dann mit dem Back-Propagation-Algorithmus verwendet werden, um die Gewichte des neuronalen Netzwerks zu aktualisieren.

 
 *** Neuronal network infos ***
 
 ** Networks **
 
 CNN takes no vector but multichanneled image 
 
 ** Layers **
 
 convolutional layer: A filter with a defined 2d-size slides over the complete image. for each image chunk the filter
slides over a dot product is produced. for each produced dot product a scalar is the result. for each filter another
feature map is created. with 6 independent filters it will produce 6 feature maps. Another conv Layer would produce
dot products from the previous conv-layer output containing dot products from the original img.

pooling layer: the function of pooling is to progressively reduce the spartial size of the representration to reduce
the amount of parameters in the network. they operatre on each feature map independently. Max pooling is the most common used technique. with a specific 2d filter it takes the highest weighted neuron
 
Fully connected layer: all neurons in the layer are connected to all neurons in the previous layer.

Relu Layer(aktivierungsfunktion):
 Multilayer perceptrons: fully connected networks - each neuron is connected to each neuron in the next layer
 

 
 