**** BACHELORARBEIT ****

**** FUNCTIONS ****

np.stack: stacks x 1D arrays into a matrix with shapes of given arrays
np.vstack: stack x arrays rowwise
np.hstack: stack x arrays columnwise



**** QUELLEN ****

allg.: https://scholar.google.de

ocr-api: https://ocr.space

deep learning: https://hackernoon.com/latest-deep-learning-ocr-with-keras-and-supervisely-in-15-minutes-34aecd630ed8

text-recognition: best path decoding algorithm

ocr-deep-learning: https://nicholastsmith.wordpress.com/2017/10/14/deep-learning-ocr-using-tensorflow-and-python/

TFANN: A neural network module containing implementations of MLP, and CNN networks in TensorFlow.

https://towardsdatascience.com/a-gentle-introduction-to-ocr-ee1469a201aa

deep learning, tesseract, ocr: https://www.learnopencv.com/deep-learning-based-text-recognition-ocr-using-tesseract-and-opencv/

**** OCR ****

The method of extracting text from images is also called Optical Character Recognition (OCR) or sometimes simply text recognition.

bsp. code: https://www.pyimagesearch.com/2017/07/10/using-tesseract-ocr-python/

Automatisierte Texterkennung innerhalb von Bildern

Deep-Learning netzwerke verwendet auf das OCR-Problem - Mit Python und Tensorflow. TFANN als Lib für CNN mit ANNC als Klasse.

OCR Texterkennung über API oder Local?

Generell: Text von jeden möglichen Bild extrahieren. Texterkennungsprozesse sind auch Straßenschilder, Captchas oder Nummerschilder zu lesen.

Attribute der OCR-Aufgaben:

1. Textdichte: sollte möglicht dicht sein. 

2. Textstruktur: Text auf Seite sollte strukturiert sein, meist in strengen Zeilen.
dense (as in printed document) or sparse (As text in the wild)


3. Schriften: Gedruckte Schriften sind einfacher als handgeschriebene Zeichen

4. Zeichentyp: Text kann in anderer Sprache verfasst sein, die sehr unterschiedlich sein kann. 

5. Artefakte: Es können Ausreißer vorkommen.

6. Ort: Einige Aufgaben enthalten aussgeschnittene/zentrierte Texte während sich in anderen Aufgaben Text an zufälligen Stellen im Bild befindet.

Nachdem die Stufe der Zeilen/wörter erkannt wurden ist können wir auf mögliche Lösungen auswählen:

1. Klassische Computer vision techniken

2. Spezialisiertes Deep Learning.

3. Standart Deep Learning (Detection)

**** TESSERACT ****

Arbeitet am besten wenn eine saubere segementierung des Vordergrundtextes zum Hintergrund. Um dies zu gewährleisten neigt man zu domänenspezifische Bildklassifikatoren und detektoren zu trainieren.

Funktioniert nur mit einer bestimmten Sorte von Image Dateien. PDF's müssen in kleine dateien gesplittet werden, damit darauf OCR angewendet werden können.

**** Beispiel Repos ****

OCR with lstm RCNN architecture
https://github.com/vinayakkailas/Deeplearning-OCR

OCR-Model
https://github.com/tensorflow/models/tree/master/research/attention_ocr

Single Shot MultiBox Detector
https://github.com/pierluigiferrari/ssd_keras


 To recognize an image containing a single character, we typically use a Convolutional Neural Network (CNN).
 Text of arbitrary length is a sequence of characters, and such problems are solved using RNNs and LSTM is a
 popular form of RNN. Read this post to learn more about LSTM.
 
 LSTM: Populärste Netzarchitektur zur Erkennung von Sequenzstrukturierten Input. Default Architektur zur
 Erkennung von Text. 
 
 *** Neuronal network infos ***
 
 ** Networks **
 
 CNN takes no vector but multichanneled image 
 
 ** Layers **
 
 convolutional layer: A filter with a defined 2d-size slides over the complete image. for each image chunk the filter
slides over a dot product is produced. for each produced dot product a scalar is the result. for each filter another
feature map is created. with 6 independent filters it will produce 6 feature maps. Another conv Layer would produce
dot products from the previous conv-layer output containing dot products from the original img.

pooling layer: the function of pooling is to progressively reduce the spartial size of the representration to reduce
the amount of parameters in the network. they operatre on each feature map independently. Max pooling is the most common
technique. with a specific 2d filter it takes the highest weighted neuron
 
Fully connected layer: all neurons in the layer are connected to all neurons in the previous layer.

Relu Layer(aktivierungsfunktion):
 Multilayer perceptrons: fully connected networks - each neuron is connected to each neuron in the next layer
 

 
 